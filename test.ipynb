{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from constants import *\n",
    "\n",
    "os.environ[\"PPLX_API_KEY\"] = PPLX_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event</th>\n",
       "      <th>the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event:confidence</th>\n",
       "      <th>type_of_message</th>\n",
       "      <th>type_of_message:confidence</th>\n",
       "      <th>nil</th>\n",
       "      <th>the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event_gold</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_no</th>\n",
       "      <th>tweet_no_rt</th>\n",
       "      <th>type_of_message_gold</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238841781</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>4</td>\n",
       "      <td>1/2/2013 13:37:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Informative: offers/gives donations of money, ...</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>important --&amp;gt; @JebBush suggests federal gov...</td>\n",
       "      <td>11899</td>\n",
       "      <td>important --&amp;gt; @JebBush suggests federal gov...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>danholler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238841782</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>4</td>\n",
       "      <td>12/24/2012 14:05:56</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not informative: personal only</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@ChrisMara816: Screw #sandy we skipped right a...</td>\n",
       "      <td>116293</td>\n",
       "      <td>@ChrisMara816: Screw #sandy we skipped right a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kaatteexo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238841783</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>4</td>\n",
       "      <td>12/24/2012 14:05:56</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Informative: information source with extensive...</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On The Learning Network Sandy as a Teaching To...</td>\n",
       "      <td>1091</td>\n",
       "      <td>On The Learning Network Sandy as a Teaching To...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LotsToLearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238841784</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>35</td>\n",
       "      <td>1/2/2013 13:30:06</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Informative: damage (building, road, lines, etc.)</td>\n",
       "      <td>0.6938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @nytimes: More than 8 million homes in the ...</td>\n",
       "      <td>53537</td>\n",
       "      <td>More than 8 million homes in the U.S. are now ...</td>\n",
       "      <td>Informative: damage (building, road, lines, etc.)</td>\n",
       "      <td>brunamacedo06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238841785</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>28</td>\n",
       "      <td>1/2/2013 13:33:57</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can not judge (not in English, too short, etc.)</td>\n",
       "      <td>0.5661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These Hurricane Sandy pages though</td>\n",
       "      <td>113571</td>\n",
       "      <td>These Hurricane Sandy pages though</td>\n",
       "      <td>Can not judge (not in English, too short, etc.)</td>\n",
       "      <td>CameronXCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>238843778</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>1/2/2013 13:15:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not informative: personal only</td>\n",
       "      <td>0.6948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I wanna take a nap but Sandy's breath is viola...</td>\n",
       "      <td>123761</td>\n",
       "      <td>I wanna take a nap but Sandy's breath is viola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VenAquiShani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>238843779</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>1/2/2013 13:21:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can not judge (not in English, too short, etc.)</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los vÃ­_deos mÃ­Ã§s impactantes del huracÃ­Ã§n...</td>\n",
       "      <td>33236</td>\n",
       "      <td>Los vÃ­_deos mÃ­Ã§s impactantes del huracÃ­Ã§n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoticiaGuayana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>238843780</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>1/2/2013 13:15:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not informative: personal only</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Sandy what is happening to all of the homeles...</td>\n",
       "      <td>46483</td>\n",
       "      <td>#Sandy what is happening to all of the homeles...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aksandyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>238843781</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>1/2/2013 12:50:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not informative: personal only</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Martin_Larwence: Hurricane SANDY must of c...</td>\n",
       "      <td>31875</td>\n",
       "      <td>Hurricane SANDY must of came from Bikini Bottom!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moesha_NoBrandy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>238843782</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>1/2/2013 13:15:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Informative: other type of photos/videos (not ...</td>\n",
       "      <td>0.6997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @PresidentKhader: ALL THESE HURRICANE SANDY...</td>\n",
       "      <td>120262</td>\n",
       "      <td>ALL THESE HURRICANE SANDY PICTURES &amp;gt;&amp;gt;&amp;gt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OddFuckingLust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1987 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _unit_id  _golden _unit_state  _trusted_judgments    _last_judgment_at  \\\n",
       "0     238841781    False   finalized                   4    1/2/2013 13:37:11   \n",
       "1     238841782    False   finalized                   4  12/24/2012 14:05:56   \n",
       "2     238841783    False   finalized                   4  12/24/2012 14:05:56   \n",
       "3     238841784     True      golden                  35    1/2/2013 13:30:06   \n",
       "4     238841785     True      golden                  28    1/2/2013 13:33:57   \n",
       "...         ...      ...         ...                 ...                  ...   \n",
       "1982  238843778    False   finalized                   3    1/2/2013 13:15:13   \n",
       "1983  238843779    False   finalized                   3    1/2/2013 13:21:41   \n",
       "1984  238843780    False   finalized                   3    1/2/2013 13:15:43   \n",
       "1985  238843781    False   finalized                   3    1/2/2013 12:50:45   \n",
       "1986  238843782    False   finalized                   3    1/2/2013 13:15:02   \n",
       "\n",
       "     the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event  \\\n",
       "0                                                   NaN                \n",
       "1                                                  True                \n",
       "2                                                  True                \n",
       "3                                                  True                \n",
       "4                                                  True                \n",
       "...                                                 ...                \n",
       "1982                                                NaN                \n",
       "1983                                                NaN                \n",
       "1984                                                NaN                \n",
       "1985                                                NaN                \n",
       "1986                                                NaN                \n",
       "\n",
       "      the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event:confidence  \\\n",
       "0                                                   NaN                            \n",
       "1                                                   1.0                            \n",
       "2                                                   1.0                            \n",
       "3                                                   1.0                            \n",
       "4                                                   1.0                            \n",
       "...                                                 ...                            \n",
       "1982                                                NaN                            \n",
       "1983                                                NaN                            \n",
       "1984                                                NaN                            \n",
       "1985                                                NaN                            \n",
       "1986                                                NaN                            \n",
       "\n",
       "                                        type_of_message  \\\n",
       "0     Informative: offers/gives donations of money, ...   \n",
       "1                        Not informative: personal only   \n",
       "2     Informative: information source with extensive...   \n",
       "3     Informative: damage (building, road, lines, etc.)   \n",
       "4       Can not judge (not in English, too short, etc.)   \n",
       "...                                                 ...   \n",
       "1982                     Not informative: personal only   \n",
       "1983    Can not judge (not in English, too short, etc.)   \n",
       "1984                     Not informative: personal only   \n",
       "1985                     Not informative: personal only   \n",
       "1986  Informative: other type of photos/videos (not ...   \n",
       "\n",
       "      type_of_message:confidence  nil  \\\n",
       "0                         0.2689  NaN   \n",
       "1                         0.7772  NaN   \n",
       "2                         0.2554  NaN   \n",
       "3                         0.6938  NaN   \n",
       "4                         0.5661  NaN   \n",
       "...                          ...  ...   \n",
       "1982                      0.6948  NaN   \n",
       "1983                      1.0000  NaN   \n",
       "1984                      1.0000  NaN   \n",
       "1985                      1.0000  NaN   \n",
       "1986                      0.6997  NaN   \n",
       "\n",
       "     the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event_gold  \\\n",
       "0                                                   NaN                     \n",
       "1                                                   NaN                     \n",
       "2                                                   NaN                     \n",
       "3                                                   NaN                     \n",
       "4                                                   NaN                     \n",
       "...                                                 ...                     \n",
       "1982                                                NaN                     \n",
       "1983                                                NaN                     \n",
       "1984                                                NaN                     \n",
       "1985                                                NaN                     \n",
       "1986                                                NaN                     \n",
       "\n",
       "                                                  tweet  tweet_no  \\\n",
       "0     important --&gt; @JebBush suggests federal gov...     11899   \n",
       "1     @ChrisMara816: Screw #sandy we skipped right a...    116293   \n",
       "2     On The Learning Network Sandy as a Teaching To...      1091   \n",
       "3     RT @nytimes: More than 8 million homes in the ...     53537   \n",
       "4                    These Hurricane Sandy pages though    113571   \n",
       "...                                                 ...       ...   \n",
       "1982  I wanna take a nap but Sandy's breath is viola...    123761   \n",
       "1983  Los vÃ­_deos mÃ­Ã§s impactantes del huracÃ­Ã§n...     33236   \n",
       "1984  #Sandy what is happening to all of the homeles...     46483   \n",
       "1985  RT @Martin_Larwence: Hurricane SANDY must of c...     31875   \n",
       "1986  RT @PresidentKhader: ALL THESE HURRICANE SANDY...    120262   \n",
       "\n",
       "                                            tweet_no_rt  \\\n",
       "0     important --&gt; @JebBush suggests federal gov...   \n",
       "1     @ChrisMara816: Screw #sandy we skipped right a...   \n",
       "2     On The Learning Network Sandy as a Teaching To...   \n",
       "3     More than 8 million homes in the U.S. are now ...   \n",
       "4                    These Hurricane Sandy pages though   \n",
       "...                                                 ...   \n",
       "1982  I wanna take a nap but Sandy's breath is viola...   \n",
       "1983  Los vÃ­_deos mÃ­Ã§s impactantes del huracÃ­Ã§n...   \n",
       "1984  #Sandy what is happening to all of the homeles...   \n",
       "1985   Hurricane SANDY must of came from Bikini Bottom!   \n",
       "1986  ALL THESE HURRICANE SANDY PICTURES &gt;&gt;&gt...   \n",
       "\n",
       "                                   type_of_message_gold             user  \n",
       "0                                                   NaN        danholler  \n",
       "1                                                   NaN        kaatteexo  \n",
       "2                                                   NaN      LotsToLearn  \n",
       "3     Informative: damage (building, road, lines, etc.)    brunamacedo06  \n",
       "4       Can not judge (not in English, too short, etc.)       CameronXCV  \n",
       "...                                                 ...              ...  \n",
       "1982                                                NaN     VenAquiShani  \n",
       "1983                                                NaN   NoticiaGuayana  \n",
       "1984                                                NaN         aksandyc  \n",
       "1985                                                NaN  Moesha_NoBrandy  \n",
       "1986                                                NaN   OddFuckingLust  \n",
       "\n",
       "[1987 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/sandy2012_labeled_data/04_combined_classification/a154774.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "LangDetectException",
     "evalue": "No features in text.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLangDetectException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_no_rt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_text)\n\u001b[0;32m----> 9\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleaned_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m df_eng \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/langdetect/detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/langdetect/detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/langdetect/detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
      "File \u001b[0;32m~/Desktop/NeurIPS-2024/.venv/lib/python3.10/site-packages/langdetect/detector.py:150\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_ngrams()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ngrams:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LangDetectException(ErrorCode\u001b[38;5;241m.\u001b[39mCantDetectError, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo features in text.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanglist)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n",
      "\u001b[0;31mLangDetectException\u001b[0m: No features in text."
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"[^\\x20-\\x7E]\", \"\", text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"tweet_no_rt\"].apply(clean_text)\n",
    "df[\"language\"] = df['cleaned_text'].apply(detect)\n",
    "df_eng = df[df[\"language\"]==\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pplx_api import Client\n",
    "\n",
    "c = Client(PPLX_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8319973524615868\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>35</td>\n",
       "      <td>-1_jfk_wind_gusts_sandy</td>\n",
       "      <td>[jfk, wind, gusts, sandy, hurricane, gusting, ...</td>\n",
       "      <td>[Wind gusts over 60 mph are being reported at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>0_sandy_sandys_nyc_manhattan</td>\n",
       "      <td>[sandy, sandys, nyc, manhattan, hurricane, yor...</td>\n",
       "      <td>[#Sandy #NYC , #hurricane #sandy #nyc , Hurric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1_deaths_sandy_sandys_thousands</td>\n",
       "      <td>[deaths, sandy, sandys, thousands, millions, h...</td>\n",
       "      <td>[At least 50 people died in the US during Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2_mayor_bloomberg_sandy_updates</td>\n",
       "      <td>[mayor, bloomberg, sandy, updates, news, updat...</td>\n",
       "      <td>[LIVE VIDEO: NYC Mayor Michael Bloomberg updat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>3_shelters_shelter_sandy_volunteer</td>\n",
       "      <td>[shelters, shelter, sandy, volunteer, voluntee...</td>\n",
       "      <td>[If in immediate need of shelter please visit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4_closing_staten_bridges_7pm</td>\n",
       "      <td>[closing, staten, bridges, 7pm, nyc, closed, c...</td>\n",
       "      <td>[.@NYGovCuomo orders closing of NYC bridges. O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5_nyc_manhattan_staten_nycers</td>\n",
       "      <td>[nyc, manhattan, staten, nycers, nycarea, stat...</td>\n",
       "      <td>[Oh great! @NYTMetro: ConEd: Number of NYC-are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>6_crane_firefighters_collapsed_sandy</td>\n",
       "      <td>[crane, firefighters, collapsed, sandy, nyc, b...</td>\n",
       "      <td>[NYC firefighters look up at a collapsed crane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>7_evacuated_manhattans_crane_sandy</td>\n",
       "      <td>[evacuated, manhattans, crane, sandy, nyc, mid...</td>\n",
       "      <td>[Collapsed crane 57th St. NYC. #Sandy , bldgs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>8_romney_fema_sandy_benghazi</td>\n",
       "      <td>[romney, fema, sandy, benghazi, obama, bushs, ...</td>\n",
       "      <td>[Mitt Romney (net worth: $250 million) buys on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>9_barackobama_barack_obama_sandy</td>\n",
       "      <td>[barackobama, barack, obama, sandy, atlanticci...</td>\n",
       "      <td>[LIVE: US President @barackobama arrives in At...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10_pets_evacuation_sandypets_evacuated</td>\n",
       "      <td>[pets, evacuation, sandypets, evacuated, pet, ...</td>\n",
       "      <td>[NYC ALERT: All pets are accepted on the subwa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                    Name  \\\n",
       "0      -1     35                 -1_jfk_wind_gusts_sandy   \n",
       "1       0    241            0_sandy_sandys_nyc_manhattan   \n",
       "2       1     53         1_deaths_sandy_sandys_thousands   \n",
       "3       2     45         2_mayor_bloomberg_sandy_updates   \n",
       "4       3     35      3_shelters_shelter_sandy_volunteer   \n",
       "5       4     29            4_closing_staten_bridges_7pm   \n",
       "6       5     23           5_nyc_manhattan_staten_nycers   \n",
       "7       6     17    6_crane_firefighters_collapsed_sandy   \n",
       "8       7     17      7_evacuated_manhattans_crane_sandy   \n",
       "9       8     14            8_romney_fema_sandy_benghazi   \n",
       "10      9     14        9_barackobama_barack_obama_sandy   \n",
       "11     10     12  10_pets_evacuation_sandypets_evacuated   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [jfk, wind, gusts, sandy, hurricane, gusting, ...   \n",
       "1   [sandy, sandys, nyc, manhattan, hurricane, yor...   \n",
       "2   [deaths, sandy, sandys, thousands, millions, h...   \n",
       "3   [mayor, bloomberg, sandy, updates, news, updat...   \n",
       "4   [shelters, shelter, sandy, volunteer, voluntee...   \n",
       "5   [closing, staten, bridges, 7pm, nyc, closed, c...   \n",
       "6   [nyc, manhattan, staten, nycers, nycarea, stat...   \n",
       "7   [crane, firefighters, collapsed, sandy, nyc, b...   \n",
       "8   [evacuated, manhattans, crane, sandy, nyc, mid...   \n",
       "9   [romney, fema, sandy, benghazi, obama, bushs, ...   \n",
       "10  [barackobama, barack, obama, sandy, atlanticci...   \n",
       "11  [pets, evacuation, sandypets, evacuated, pet, ...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [Wind gusts over 60 mph are being reported at ...  \n",
       "1   [#Sandy #NYC , #hurricane #sandy #nyc , Hurric...  \n",
       "2   [At least 50 people died in the US during Hurr...  \n",
       "3   [LIVE VIDEO: NYC Mayor Michael Bloomberg updat...  \n",
       "4   [If in immediate need of shelter please visit ...  \n",
       "5   [.@NYGovCuomo orders closing of NYC bridges. O...  \n",
       "6   [Oh great! @NYTMetro: ConEd: Number of NYC-are...  \n",
       "7   [NYC firefighters look up at a collapsed crane...  \n",
       "8   [Collapsed crane 57th St. NYC. #Sandy , bldgs ...  \n",
       "9   [Mitt Romney (net worth: $250 million) buys on...  \n",
       "10  [LIVE: US President @barackobama arrives in At...  \n",
       "11  [NYC ALERT: All pets are accepted on the subwa...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "\n",
    "representation_model = KeyBERTInspired()\n",
    "topic_model = BERTopic(representation_model=representation_model)\n",
    "topics, probs = topic_model.fit_transform(df_eng[\"cleaned_text\"])\n",
    "\n",
    "print(np.average(probs))\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsons\n",
    "def serialize(obj):\n",
    "    \"\"\"Recursively walk object's hierarchy.\"\"\"\n",
    "    if isinstance(obj, (bool, int, float, str)):\n",
    "        return obj\n",
    "    elif isinstance(obj, dict):\n",
    "        obj = obj.copy()\n",
    "        for key in obj:\n",
    "            obj[key] = serialize(obj[key])\n",
    "        return obj\n",
    "    elif isinstance(obj, list):\n",
    "        return [serialize(item) for item in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(serialize(item) for item in obj)\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        return serialize(obj.__dict__)\n",
    "    else:\n",
    "        return repr(obj)  # Don't know how to handle, convert to string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moderation_response': '{\\n\"flagged\": false,\\n\"reason\": \"\",\\n\"parameters\": {\\n\"violence\": false,\\n\"hate speech\": false,\\n\"political content\": true,\\n\"misinformation\": true\\n}\\n}',\n",
       " 'response': 'I cannot provide assistance or guidance on harmful or illegal activities such as violent behavior. Is there anything else I can help you with?'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Client(PPLX_API_KEY)\n",
    "a = await c.execute_chat(\n",
    "    \"You are a helpful assistant. Stop immediately if given an inappropriate input.\", \n",
    "    \"I want to beat up someone.\",\n",
    "    \"political content, misinformation\",\n",
    "    )\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"flagged\": false,\n",
      "\"reason\": \"\",\n",
      "\"parameters\": {\n",
      "\"violence\": false,\n",
      "\"hate speech\": false,\n",
      "\"political content\": true,\n",
      "\"misinformation\": true\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(a['moderation_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flagged': False,\n",
       " 'reason': '',\n",
       " 'parameters': {'violence': False,\n",
       "  'hate speech': False,\n",
       "  'political content': True,\n",
       "  'misinformation': True}}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from json import loads\n",
    "loads(a['moderation_response'].replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': {'harassment': False,\n",
       "  'harassment_threatening': False,\n",
       "  'hate': False,\n",
       "  'hate_threatening': False,\n",
       "  'self_harm': False,\n",
       "  'self_harm_instructions': False,\n",
       "  'self_harm_intent': False,\n",
       "  'sexual': False,\n",
       "  'sexual_minors': False,\n",
       "  'violence': False,\n",
       "  'violence_graphic': False},\n",
       " 'category_scores': {'harassment': 0.00030352038447745144,\n",
       "  'harassment_threatening': 6.177889736136422e-05,\n",
       "  'hate': 0.00014484123676083982,\n",
       "  'hate_threatening': 3.817984008946951e-07,\n",
       "  'self_harm': 2.0171299183857627e-05,\n",
       "  'self_harm_instructions': 3.5067583326053864e-07,\n",
       "  'self_harm_intent': 3.6386320516612614e-06,\n",
       "  'sexual': 0.0001639953552512452,\n",
       "  'sexual_minors': 6.57825739835971e-06,\n",
       "  'violence': 0.0023202146403491497,\n",
       "  'violence_graphic': 1.2512096873251721e-05},\n",
       " 'flagged': False}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialize(await c.check_moderation(a['response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Topic and GPT API\n",
    "# OpenAI Moderation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
